import os
import json
from datetime import datetime, date
from typing import Dict, List, Set, Tuple, Optional, Iterable, Any

import psycopg
from psycopg.rows import dict_row
from pywebpush import webpush, WebPushException

import tennis_core
import crawl_goyang


# =========================================================
# Utils
# =========================================================
def utcnow() -> datetime:
    return datetime.utcnow()


def to_yyyymmdd(s: str) -> str:
    """
    alarms.dateê°€ "YYYY-MM-DD" ë˜ëŠ” "YYYYMMDD" ë‘˜ ë‹¤ ì˜¬ ìˆ˜ ìˆìŒ.
    availabilityëŠ” "YYYYMMDD" í‚¤ë¥¼ ì“°ëŠ” ê±¸ ì „ì œë¡œ ë§ì¶˜ë‹¤.
    """
    if not s:
        return ""
    s = s.strip()
    if "-" in s:
        return s.replace("-", "")
    return s


def yyyymmdd_to_date(yyyymmdd: str) -> date:
    return date(int(yyyymmdd[0:4]), int(yyyymmdd[4:6]), int(yyyymmdd[6:8]))


def date_to_yyyymmdd(d: date) -> str:
    return d.strftime("%Y%m%d")


def get_court_group(title: str, facility_id: str = "") -> str:
    import re
    base = re.sub(r"\[.*?\]", "", title or "").split("í…Œë‹ˆìŠ¤ì¥")[0].strip()

    if str(facility_id).startswith("yongin:"):
        return f"ìš©ì¸|{base}"
    if str(facility_id).startswith("goyang:"):
        return f"ê³ ì–‘|{base}"
    return base

def slot_key_from_time(t: Any) -> str:
    """
    tennis_core ê²°ê³¼ ìŠ¬ë¡¯ì´ strì´ ì•„ë‹ˆë¼ dictë¡œ ì˜¤ëŠ” ì¼€ì´ìŠ¤ ëŒ€ì‘.
    ê°€ëŠ¥í•œ í‚¤ í›„ë³´:
    - time / startTime / start_time / hhmm / label / timeContent
    - court / courtNo / court_name ê°™ì´ ì½”íŠ¸ êµ¬ë¶„
    ìµœì¢… slot_keyëŠ” "TIME" ë˜ëŠ” "TIME|COURT" í˜•íƒœ
    """
    if t is None:
        return ""
    if isinstance(t, str):
        return t.strip()

    if isinstance(t, dict):
        time_val = (
            t.get("time")
            or t.get("startTime")
            or t.get("start_time")
            or t.get("stime")
            or t.get("label")
            or t.get("timeContent")
        )
        if isinstance(time_val, dict):
            time_val = time_val.get("time") or time_val.get("label")
        time_str = str(time_val).strip() if time_val is not None else ""

        court_val = (
            t.get("court")
            or t.get("courtNo")
            or t.get("court_no")
            or t.get("courtName")
            or t.get("court_name")
        )
        court_str = str(court_val).strip() if court_val is not None else ""

        if court_str and time_str:
            return f"{time_str}|{court_str}"
        return time_str

    return str(t).strip()


def slot_obj_for_frontend(t: Any, fallback_resve_id: str) -> Dict[str, Any]:
    """
    availability_cache.slots_jsonì— ë„£ì„ í”„ë¡ íŠ¸ìš© ìŠ¬ë¡¯ ê°ì²´.
    í”„ë¡ íŠ¸ëŠ” {timeContent, resveId}ë¥¼ ê¸°ëŒ€.
    """
    if isinstance(t, dict):
        # ê°€ëŠ¥í•œ í‚¤ë¥¼ timeContent/resveIdë¡œ ì •ê·œí™”
        time_content = (
            t.get("timeContent")
            or t.get("label")
            or t.get("time")
            or t.get("startTime")
            or t.get("start_time")
            or t.get("stime")
        )
        resve_id = t.get("resveId") or t.get("resve_id") or fallback_resve_id
        obj = dict(t)
        obj["timeContent"] = str(time_content) if time_content is not None else slot_key_from_time(t)
        obj["resveId"] = str(resve_id) if resve_id is not None else fallback_resve_id
        return obj

    # str/ê¸°íƒ€
    return {"timeContent": slot_key_from_time(t), "resveId": fallback_resve_id}


# =========================================================
# DB schema (ì¶”ê°€/ì¡°íšŒìš©ë§Œ: ê¸°ì¡´ í…Œì´ë¸”ì€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
# =========================================================
SCHEMA_SQL = """
-- í”„ë¡ íŠ¸ìš© ì‹œì„¤ ë©”íƒ€ (ì—†ìœ¼ë©´ ìƒì„±)
create table if not exists public.facilities (
  facility_id text primary key,
  title text not null,
  location text,
  updated_at timestamptz not null default now()
);

-- í”„ë¡ íŠ¸ìš© availability ìºì‹œ (ì—†ìœ¼ë©´ ìƒì„±)
create table if not exists public.availability_cache (
  facility_id text not null references public.facilities(facility_id) on delete cascade,
  date_ymd date not null,
  slots_json jsonb not null default '[]'::jsonb,
  updated_at timestamptz not null default now(),
  primary key (facility_id, date_ymd)
);

create index if not exists idx_avcache_date on public.availability_cache(date_ymd);
"""

def ensure_extra_schema(conn: psycopg.Connection) -> None:
    with conn.cursor() as cur:
        cur.execute(SCHEMA_SQL)
    conn.commit()

def _ns_yongin_id(rid: str) -> str:
    return f"yongin:{rid}"

def _ns_goyang_id(kind: str, key: str) -> str:
    # kind: "gytennis" / "daehwa"
    return f"goyang:{kind}:{key}" if key else f"goyang:{kind}"

def _strip_yongin_resve_id(fid: str) -> str:
    # yongin:123 -> 123 (í”„ë¡ íŠ¸ ì˜ˆì•½ ë§í¬ìš©)
    if isinstance(fid, str) and fid.startswith("yongin:"):
        return fid.split(":", 1)[1]
    return str(fid)

def _ymd_to_yyyymmdd(s: str) -> str:
    # "YYYY-MM-DD" or "YYYYMMDD" -> "YYYYMMDD"
    return to_yyyymmdd(s)
# =========================================================
# Crawl adapter
# =========================================================
def _clean_goyang_title(title: str) -> str:
    if not title:
        return title
    # "ê³ ì–‘íŠ¹ë¡€ì‹œí…Œë‹ˆìŠ¤í˜‘íšŒ " ì œê±° (ê³µë°± ìœ ë¬´ ëª¨ë‘ ëŒ€ì‘)
    return title.replace("ê³ ì–‘íŠ¹ë¡€ì‹œí…Œë‹ˆìŠ¤í˜‘íšŒ", "").strip()


def crawl_all() -> Tuple[Dict[str, Any], Dict[str, Dict[str, List[Any]]]]:
    """
    ìµœì¢… ë°˜í™˜:
      facilities: { facility_id(text): {title, location, ...} }
      availability: { facility_id: { "YYYYMMDD": [slot, ...] } }
    """
    target = (os.getenv("RUN_TARGET") or "all").strip().lower()

    facilities: Dict[str, Any] = {}
    availability: Dict[str, Dict[str, List[Any]]] = {}

    # -----------------------------
    # (A) ìš©ì¸ (tennis_core)
    # -----------------------------
    if target in ("all", "yongin"):
        y_fac, y_av = tennis_core.run_all()

        for rid, meta in (y_fac or {}).items():
            rid = str(rid)
            fid = _ns_yongin_id(rid)
            facilities[fid] = meta

        for rid, daymap in (y_av or {}).items():
            rid = str(rid)
            fid = _ns_yongin_id(rid)
            availability[fid] = daymap or {}

    # -----------------------------
    # (B) ê³ ì–‘ (crawl_goyang)
    # -----------------------------
    if target in ("all", "goyang"):
        out_g1 = crawl_goyang.crawl_gytennis()

        # âœ… daehwaëŠ” ë¡œê·¸ì¸ì •ë³´ ì—†ìœ¼ë©´ ìŠ¤í‚µ(ì‹¤íŒ¨ë¡œ ì „ì²´ ì¢…ë£Œ ë°©ì§€)
        try:
            out_g2 = crawl_goyang.crawl_daehwa()
        except Exception as e:
            print("[DAEHWA] skipped:", e)
            out_g2 = {"facilities": {}, "availability": {}}

        g_fac = {**out_g1.get("facilities", {}), **out_g2.get("facilities", {})}
        g_av  = {**out_g1.get("availability", {}), **out_g2.get("availability", {})}

        # 1) ì‹œì„¤ id ë§¤í•‘ + title ì •ë¦¬(ì ‘ë‘ì–´ ì œê±°)
        for raw_fid, meta in (g_fac or {}).items():
            raw_fid = str(raw_fid)

            if raw_fid.startswith("gy-gytennis-"):
                cv = raw_fid.split("gy-gytennis-", 1)[1]
                fid = _ns_goyang_id("gytennis", cv)
            elif raw_fid == "gy-daehwa":
                fid = "goyang:daehwa"
            else:
                fid = f"goyang:{raw_fid}"

            meta2 = dict(meta or {})
            meta2["title"] = _clean_goyang_title(meta2.get("title", ""))
            facilities[fid] = meta2

        # 2) availability í‚¤ ë³€í™˜ + reserveUrl ë„£ê¸°
        for raw_fid, daymap in (g_av or {}).items():
            raw_fid = str(raw_fid)

            if raw_fid.startswith("gy-gytennis-"):
                cv = raw_fid.split("gy-gytennis-", 1)[1]
                fid = _ns_goyang_id("gytennis", cv)
                kind = "gytennis"
            elif raw_fid == "gy-daehwa":
                fid = "goyang:daehwa"
                kind = "daehwa"
                cv = None
            else:
                fid = f"goyang:{raw_fid}"
                kind = "other"
                cv = None

            new_daymap: Dict[str, List[Any]] = {}
            for ymd, slots in (daymap or {}).items():
                ymd = str(ymd)
                yyyymmdd = _ymd_to_yyyymmdd(ymd)
                if len(yyyymmdd) != 8:
                    continue

                enriched = []
                for s in (slots or []):
                    if isinstance(s, dict):
                        ss = dict(s)

                        # âœ… ê³ ì–‘ í´ë¦­ ë§í¬
                        if kind == "gytennis" and cv:
                            ymd_dash = ymd if "-" in ymd else f"{yyyymmdd[:4]}-{yyyymmdd[4:6]}-{yyyymmdd[6:8]}"
                            ss["reserveUrl"] = f"https://www.gytennis.or.kr/daily/{cv}/{ymd_dash}"
                        elif kind == "daehwa":
                            ss["reserveUrl"] = "https://daehwa.gys.or.kr:451/rent/tennis_rent.php"

                        enriched.append(ss)
                    else:
                        enriched.append(s)

                if enriched:
                    new_daymap[yyyymmdd] = enriched

            if new_daymap:
                availability[fid] = new_daymap

    return facilities, availability

# =========================================================
# DB write: facilities / availability_cache (í”„ë¡ íŠ¸ìš©)
# =========================================================
def upsert_facilities_for_frontend(conn: psycopg.Connection, facilities: Dict[str, Any]) -> None:
    ts = utcnow()
    rows = []
    for fid, v in facilities.items():
        fid = str(fid)
        if isinstance(v, dict):
            title = v.get("title") or v.get("name") or v.get("facility_name") or f"RID {fid}"
            location = v.get("location") or ""
        else:
            title = str(v) if v is not None else f"RID {fid}"
            location = ""
        rows.append((fid, title, location, ts))

    if not rows:
        return

    with conn.cursor() as cur:
        cur.executemany(
            """
            insert into public.facilities (facility_id, title, location, updated_at)
            values (%s, %s, %s, %s)
            on conflict (facility_id)
            do update set title=excluded.title, location=excluded.location, updated_at=excluded.updated_at
            """,
            rows,
        )
    conn.commit()


def upsert_availability_cache_for_frontend(
    conn: psycopg.Connection,
    facilities: Dict[str, Any],
    availability: Dict[str, Dict[str, List[Any]]],
) -> None:
    """
    availability_cacheëŠ” í”„ë¡ íŠ¸ê°€ /api/data ëŒ€ì‹  ì½ëŠ” ìš©ë„.
    slots_jsonì€ [{"timeContent":"..","resveId":".."}, ...]
    """
    ts = utcnow()
    rows = []

    for fid, day_map in availability.items():
        fid = str(fid)
        for ymd, slots in (day_map or {}).items():
            ymd = (ymd or "").strip()
            if len(ymd) != 8:
                continue
            d = yyyymmdd_to_date(ymd)

            # reserve linkì˜ resveIdëŠ” ìŠ¬ë¡¯ë³„ë¡œ ë” ì •í™•í•  ìˆ˜ ìˆì§€ë§Œ,
            # ìµœì†Œí•œ "ì‹œì„¤ idë¡œ ë§í¬ ìƒì„±"ë„ ê°€ëŠ¥í•˜ê²Œ fallback ì²˜ë¦¬
            fallback_resve_id = _strip_yongin_resve_id(fid)

            arr = [slot_obj_for_frontend(s, fallback_resve_id) for s in (slots or []) if slot_key_from_time(s)]
            rows.append((fid, d, json.dumps(arr, ensure_ascii=False), ts))

    if not rows:
        return

    with conn.cursor() as cur:
        cur.executemany(
            """
            insert into public.availability_cache (facility_id, date_ymd, slots_json, updated_at)
            values (%s, %s, %s::jsonb, %s)
            on conflict (facility_id, date_ymd)
            do update set slots_json=excluded.slots_json, updated_at=excluded.updated_at
            """,
            rows,
        )
    conn.commit()


# =========================================================
# DB read (batch)
# =========================================================
def load_push_subscriptions(conn: psycopg.Connection, sub_ids: List[str]) -> Dict[str, dict]:
    """
    push_subscriptions: id(subscription_id) -> pywebpush subscription_info
    """
    if not sub_ids:
        return {}
    with conn.cursor(row_factory=dict_row) as cur:
        cur.execute(
            """
            select id, endpoint, p256dh, auth
            from public.push_subscriptions
            where id = any(%s)
            """,
            (sub_ids,),
        )
        rows = cur.fetchall()

    m = {}
    for r in rows:
        sid = r["id"]
        m[sid] = {"endpoint": r["endpoint"], "keys": {"p256dh": r["p256dh"], "auth": r["auth"]}}
    return m


def load_alarms(conn: psycopg.Connection) -> List[dict]:
    """
    alarms: subscription_id, court_group, date(text)
    """
    with conn.cursor(row_factory=dict_row) as cur:
        cur.execute(
            """
            select subscription_id, court_group, date
            from public.alarms
            """
        )
        return cur.fetchall()


def preload_baseline(conn: psycopg.Connection, keys: List[Tuple[str, str, str]]) -> Dict[Tuple[str, str, str], Set[str]]:
    """
    baseline_slots: subscription_id, court_group, date(char/text), time_content
    keys: [(sub_id, court_group, yyyymmdd), ...]
    return: key -> set(time_content)
    """
    if not keys:
        return {}

    # UNNESTë¡œ 3ì—´ join
    sub_ids = [k[0] for k in keys]
    groups = [k[1] for k in keys]
    dates = [k[2] for k in keys]

    with conn.cursor(row_factory=dict_row) as cur:
        cur.execute(
            """
            with q as (
              select * from unnest(%s::text[], %s::text[], %s::text[])
                as t(subscription_id, court_group, date)
            )
            select b.subscription_id, b.court_group, b.date, b.time_content
            from public.baseline_slots b
            join q
              on q.subscription_id = b.subscription_id
             and q.court_group = b.court_group
             and q.date = b.date
            """,
            (sub_ids, groups, dates),
        )
        rows = cur.fetchall()

    m: Dict[Tuple[str, str, str], Set[str]] = {}
    for r in rows:
        key = (r["subscription_id"], r["court_group"], r["date"])
        m.setdefault(key, set()).add(r["time_content"])
    return m


def insert_baseline(conn: psycopg.Connection, sub_id: str, court_group: str, ymd: str, slot_keys: Iterable[str]) -> None:
    """
    baseline_slotsì— í˜„ì¬ ìŠ¬ë¡¯ì„ baselineìœ¼ë¡œ ë°•ì•„ ë„£ìŒ.
    (ì²« ì‹¤í–‰/ì²« ì•ŒëŒ ë“±ë¡ ì‹œ ê¸°ì¡´ ìŠ¬ë¡¯ì€ ì•Œë¦¼ ì•ˆ ë³´ë‚´ê¸°ìš©)
    """
    rows = []
    for sk in slot_keys:
        if not sk:
            continue
        rows.append((sub_id, court_group, ymd, sk))

    if not rows:
        return

    with conn.cursor() as cur:
        cur.executemany(
            """
            insert into public.baseline_slots (subscription_id, court_group, date, time_content)
            values (%s, %s, %s, %s)
            on conflict do nothing
            """,
            rows,
        )
    conn.commit()


def preload_sent_slots(conn: psycopg.Connection, sub_ids: List[str], slot_keys: List[str]) -> Dict[str, Set[str]]:
    """
    sent_slots: subscription_id, slot_key
    í•œë²ˆì— preloadí•´ì„œ per-user DB hit ì œê±°
    """
    if not sub_ids or not slot_keys:
        return {sid: set() for sid in sub_ids}

    with conn.cursor(row_factory=dict_row) as cur:
        cur.execute(
            """
            select subscription_id, slot_key
            from public.sent_slots
            where subscription_id = any(%s)
              and slot_key = any(%s)
            """,
            (sub_ids, slot_keys),
        )
        rows = cur.fetchall()

    m: Dict[str, Set[str]] = {sid: set() for sid in sub_ids}
    for r in rows:
        m.setdefault(r["subscription_id"], set()).add(r["slot_key"])
    return m


def bulk_mark_sent(conn: psycopg.Connection, sent_rows: List[Tuple[str, str]]) -> None:
    """
    sent_slots bulk insert
    sent_rows: [(subscription_id, slot_key), ...]
    """
    if not sent_rows:
        return
    with conn.cursor() as cur:
        cur.executemany(
            """
            insert into public.sent_slots (subscription_id, slot_key, sent_at)
            values (%s, %s, now())
            on conflict do nothing
            """,
            sent_rows,
        )
    conn.commit()


def bulk_upsert_slots_snapshot(conn: psycopg.Connection, snapshot_rows: List[Tuple[str, date, str]]) -> None:
    """
    slots_snapshot: facility_id, date_ymd, slot_key
    (first_seen_at/last_seen_at ê°±ì‹ )
    """
    if not snapshot_rows:
        return
    ts = utcnow()
    with conn.cursor() as cur:
        cur.executemany(
            """
            insert into public.slots_snapshot (facility_id, date_ymd, slot_key, first_seen_at, last_seen_at)
            values (%s, %s, %s, %s, %s)
            on conflict (facility_id, date_ymd, slot_key)
            do update set last_seen_at = excluded.last_seen_at
            """,
            [(fid, d, sk, ts, ts) for (fid, d, sk) in snapshot_rows],
        )
    conn.commit()


# =========================================================
# Push
# =========================================================
def send_push(subscription_info: dict, title: str, body: str) -> None:
    vapid_private = os.environ["VAPID_PRIVATE_KEY"]
    vapid_subject = os.environ["VAPID_SUBJECT"]
    payload = json.dumps({"title": title, "body": body}, ensure_ascii=False)

    webpush(
        subscription_info=subscription_info,
        data=payload,
        vapid_private_key=vapid_private,
        vapid_claims={"sub": vapid_subject},
    )


# =========================================================
# Main
# =========================================================
def main() -> None:
    database_url = os.environ["DATABASE_URL"]
    _ = os.environ.get("VAPID_PUBLIC_KEY", "")
    _ = os.environ["VAPID_PRIVATE_KEY"]
    _ = os.environ["VAPID_SUBJECT"]

    ts_now = utcnow()

    # ê²°ê³¼ ëˆ„ì (ë§ˆì§€ë§‰ì— bulk flush)
    snapshot_rows: List[Tuple[str, date, str]] = []   # (facility_id, date_ymd, slot_key)
    sent_rows: List[Tuple[str, str]] = []            # (subscription_id, slot_key)

    with psycopg.connect(database_url) as conn:
        # í”„ë¡ íŠ¸ìš© í…Œì´ë¸”ë§Œ (ì—†ìœ¼ë©´) ì¶”ê°€ ìƒì„±
        ensure_extra_schema(conn)

        # 1) í¬ë¡¤ë§
        facilities, availability = crawl_all()
        print(f"[INFO] crawled facilities={len(availability)}")

        # 2) í”„ë¡ íŠ¸ìš© ì €ì¥ (ì‹œì„¤/availability_cache)
        try:
            upsert_facilities_for_frontend(conn, facilities)
            upsert_availability_cache_for_frontend(conn, facilities, availability)
        except Exception as e:
            # í”„ë¡ íŠ¸ìš© ì €ì¥ì´ ì‹¤íŒ¨í•´ë„ ì•Œë¦¼ì€ ê³„ì† ìˆ˜í–‰í•  ìˆ˜ ìˆê²Œ í•œë‹¤
            print(f"[WARN] frontend cache save failed: {e}")

        # 3) alarms preload
        alarms = load_alarms(conn)
        if not alarms:
            print("[SUMMARY] alarms=0 (no work)")
            return

        # 4) subscription_id ëª©ë¡ -> push_subscriptions preload
        sub_ids = sorted({str(a["subscription_id"]) for a in alarms if a.get("subscription_id")})
        push_map = load_push_subscriptions(conn, sub_ids)

        # 5) alarmsë¥¼ (subscription_id, court_group, yyyymmdd) í‚¤ë¡œ ì •ê·œí™”
        alarm_keys: List[Tuple[str, str, str]] = []
        for a in alarms:
            sid = str(a["subscription_id"])
            group = (a.get("court_group") or "").strip()
            ymd = to_yyyymmdd(a.get("date") or "")
            if not sid or not group or len(ymd) != 8:
                continue
            alarm_keys.append((sid, group, ymd))

        if not alarm_keys:
            print("[SUMMARY] alarms valid=0 (bad date/group)")
            return

        # 6) baseline preload (í•œë²ˆì—)
        baseline_map = preload_baseline(conn, alarm_keys)

        # 7) court_groupë³„ë¡œ, í•´ë‹¹ ë‚ ì§œ ìŠ¬ë¡¯ì„ ë¹ ë¥´ê²Œ ëª¨ìœ¼ê¸° ìœ„í•œ ì¸ë±ìŠ¤
        # group -> facility_ids
        group_to_fids: Dict[str, List[str]] = {}
        for fid, meta in facilities.items():
            fid = str(fid)
            title = meta.get("title") if isinstance(meta, dict) else str(meta)
            g = get_court_group(title, fid)
            group_to_fids.setdefault(g, []).append(fid)

        # 8) ëª¨ë“  ì•ŒëŒì—ì„œ "í˜„ì¬ ìŠ¬ë¡¯ í›„ë³´(slot_key)"ë¥¼ ë¨¼ì € ëª¨ì•„ì„œ
        #    sent_slotsë¥¼ í•œë²ˆì— preload í•˜ê¸° ìœ„í•œ candidate set ìƒì„±
        #    (sent_slots preloadëŠ” subscription_id+slot_key ì¡°í•©ì„ batchë¡œ í•œ ë²ˆì—)
        key_to_current_slots: Dict[Tuple[str, str, str], Set[str]] = {}
        all_candidate_slot_keys: Set[str] = set()

        for (sid, group, ymd) in alarm_keys:
            fids = group_to_fids.get(group, [])
            if not fids:
                key_to_current_slots[(sid, group, ymd)] = set()
                continue

            cur_slots: Set[str] = set()
            for fid in fids:
                day_map = availability.get(str(fid)) or {}
                slots = day_map.get(ymd) or []
                for t in slots:
                    sk = slot_key_from_time(t)
                    if sk:
                        cur_slots.add(sk)

                        # sent_slotsëŠ” slot_keyë§Œ ì €ì¥í•˜ë‹ˆê¹Œ
                        # (facility êµ¬ë¶„ê¹Œì§€ í•„ìš”í•˜ë©´ slot_key ì„¤ê³„ë¥¼ ë” ê³ ìœ í•˜ê²Œ í•´ì•¼ í•¨)
                        all_candidate_slot_keys.add(sk)

            key_to_current_slots[(sid, group, ymd)] = cur_slots

        # 9) sent_slots preload (í•œ ë²ˆì—)
        sent_map = preload_sent_slots(conn, sub_ids, sorted(all_candidate_slot_keys))

        # 10) ì•Œë¦¼ ì²˜ë¦¬
        push_requests = 0
        baseline_inserts = 0
        added_total = 0

        for (sid, group, ymd) in alarm_keys:
            cur_slots = key_to_current_slots.get((sid, group, ymd), set())

            # push êµ¬ë…ì´ ì—†ìœ¼ë©´ ìŠ¤í‚µ
            sub_info = push_map.get(sid)
            if not sub_info:
                continue

            # baselineì´ ì—†ë‹¤ë©´: "ì²« ì‹¤í–‰"ìœ¼ë¡œ ë³´ê³  baseline ì €ì¥ í›„ ì•Œë¦¼ ìŠ¤í‚µ
            base_key = (sid, group, ymd)
            baseline = baseline_map.get(base_key)
            if not baseline:
                if cur_slots:
                    insert_baseline(conn, sid, group, ymd, cur_slots)
                    baseline_inserts += 1
                    baseline_map[base_key] = set(cur_slots)
                continue

            # baseline ì´í›„ ì‹ ê·œ ìŠ¬ë¡¯ = cur - baseline
            added = cur_slots - baseline
            if not added:
                continue

            # ì´ë¯¸ ë³´ë‚¸ ìŠ¬ë¡¯ ì œì™¸
            already_sent = sent_map.get(sid, set())
            to_send = [sk for sk in sorted(added) if sk not in already_sent]
            if not to_send:
                continue

            # í‘¸ì‹œ ë©”ì‹œì§€ êµ¬ì„±
            # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ìš”ì•½
            preview = ", ".join(to_send[:6])
            more = "" if len(to_send) <= 6 else f" ì™¸ {len(to_send)-6}ê°œ"

            title = "ğŸ¾ ì˜ˆì•½ ì˜¤í”ˆ"
            body = f"{group} {ymd[4:6]}/{ymd[6:8]} ì‹ ê·œ ìŠ¬ë¡¯: {preview}{more}"

            try:
                send_push(sub_info, title, body)
                push_requests += 1
                added_total += len(to_send)

                # sent_slots bulk insertë¥¼ ìœ„í•´ ëˆ„ì 
                for sk in to_send:
                    sent_rows.append((sid, sk))
                    sent_map.setdefault(sid, set()).add(sk)

            except WebPushException as e:
                code = getattr(getattr(e, "response", None), "status_code", None)
                print(f"[PUSH_FAIL] sid={sid} group={group} date={ymd} status={code} err={e}")

        # 11) slots_snapshot ê°±ì‹ (ì‹œì„¤/ë‚ ì§œ ë‹¨ìœ„ë¡œëŠ” availability ê¸°ì¤€ìœ¼ë¡œ ê³„ì† ê°±ì‹ )
        #     (ì´ í…Œì´ë¸”ì€ â€œì›ë³¸ ìŠ¬ë¡¯ ë³€í™” ê¸°ë¡â€ ìš©ë„ë¼ alarmsì™€ ë³„ê°œë¡œ ìœ ì§€ ê°€ëŠ¥)
        for fid, day_map in (availability or {}).items():
            fid = str(fid)
            for ymd, slots in (day_map or {}).items():
                if not ymd or len(ymd) != 8:
                    continue
                d = yyyymmdd_to_date(ymd)
                for t in (slots or []):
                    sk = slot_key_from_time(t)
                    if sk:
                        snapshot_rows.append((fid, d, sk))

        # 12) bulk flush
        try:
            bulk_upsert_slots_snapshot(conn, snapshot_rows)
        except Exception as e:
            print(f"[WARN] slots_snapshot bulk upsert failed: {e}")

        try:
            bulk_mark_sent(conn, sent_rows)
        except Exception as e:
            print(f"[WARN] sent_slots bulk insert failed: {e}")

        print(f"[SUMMARY] alarms={len(alarm_keys)} baseline_inserts={baseline_inserts} push_requests={push_requests} sent_slots_added={added_total}")


if __name__ == "__main__":
    main()

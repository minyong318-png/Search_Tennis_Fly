import os
import json
from datetime import datetime, date
from typing import Dict, List, Set, Tuple, Optional, Iterable

import psycopg
from psycopg.rows import tuple_row
from pywebpush import webpush, WebPushException

import tennis_core


# -------------------------
# Utils
# -------------------------
def utcnow() -> datetime:
    return datetime.utcnow()


def ymd_str_to_date(yyyymmdd: str) -> date:
    return date(int(yyyymmdd[0:4]), int(yyyymmdd[4:6]), int(yyyymmdd[6:8]))


def slot_key_from_time(t) -> str:
    """
    tennis_core ê²°ê³¼ ìŠ¬ë¡¯ì´ strì´ ì•„ë‹ˆë¼ dictë¡œ ì˜¤ëŠ” ì¼€ì´ìŠ¤ ëŒ€ì‘.
    ê°€ëŠ¥í•œ í‚¤ í›„ë³´:
      - time / startTime / start_time / hhmm / label
      - court / courtNo / court_name ê°™ì´ ì½”íŠ¸ êµ¬ë¶„
    ìµœì¢… slot_keyëŠ” "TIME" ë˜ëŠ” "TIME|COURT" í˜•íƒœë¡œ ë§Œë“ ë‹¤.
    """
    if t is None:
        return ""

    # 1) ë¬¸ìì—´ì´ë©´ ê·¸ëŒ€ë¡œ
    if isinstance(t, str):
        return t.strip()

    # 2) dictë©´ time í•„ë“œ ë½‘ê¸°
    if isinstance(t, dict):
        # ì‹œê°„ í›„ë³´ í‚¤ë“¤
        time_val = (
            t.get("time")
            or t.get("startTime")
            or t.get("start_time")
            or t.get("stime")
            or t.get("label")
        )

        # ì‹œê°„ì´ ë˜ dictë¡œ ì˜¤ë©´(ë“œë¬¸ ì¼€ì´ìŠ¤) ë¬¸ìì—´í™”
        if isinstance(time_val, dict):
            time_val = time_val.get("time") or time_val.get("label")

        time_str = str(time_val).strip() if time_val is not None else ""

        # ì½”íŠ¸ í›„ë³´ í‚¤ë“¤(ìˆìœ¼ë©´ ë¶™ì—¬ì„œ slot_idë¥¼ ë” ê³ ìœ í•˜ê²Œ)
        court_val = (
            t.get("court")
            or t.get("courtNo")
            or t.get("court_no")
            or t.get("courtName")
            or t.get("court_name")
        )
        court_str = str(court_val).strip() if court_val is not None else ""

        if court_str and time_str:
            return f"{time_str}|{court_str}"
        return time_str

    # 3) ê·¸ ì™¸ëŠ” ë¬¸ìì—´ë¡œ
    return str(t).strip()



# -------------------------
# DB schema (minimal)
# -------------------------
SCHEMA_SQL = """
create table if not exists push_endpoints (
  user_id text primary key,
  endpoint text not null,
  p256dh text not null,
  auth text not null,
  updated_at timestamptz not null default now()
);

create table if not exists subscriptions (
  id bigserial primary key,
  user_id text not null,
  facility_id text not null,
  date_ymd date not null,
  enabled boolean not null default true,
  created_at timestamptz not null default now()
);

create index if not exists idx_subscriptions_fac_date
  on subscriptions (facility_id, date_ymd)
  where enabled = true;

create table if not exists slots_snapshot (
  facility_id text not null,
  date_ymd date not null,
  slot_key text not null,
  first_seen_at timestamptz not null default now(),
  last_seen_at timestamptz not null default now(),
  primary key (facility_id, date_ymd, slot_key)
);

create index if not exists idx_slots_snapshot_fac_date
  on slots_snapshot (facility_id, date_ymd);

create table if not exists sent_log (
  user_id text not null,
  facility_id text not null,
  date_ymd date not null,
  slot_key text not null,
  sent_at timestamptz not null default now(),
  primary key (user_id, facility_id, date_ymd, slot_key)
);
"""


def ensure_schema(conn: psycopg.Connection) -> None:
    with conn.cursor() as cur:
        cur.execute(SCHEMA_SQL)
    conn.commit()


# -------------------------
# Load data from DB (batch)
# -------------------------
def load_all_endpoints(conn: psycopg.Connection) -> Dict[str, dict]:
    """
    returns: user_id -> subscription_info dict for pywebpush
    """
    with conn.cursor(row_factory=tuple_row) as cur:
        cur.execute("select user_id, endpoint, p256dh, auth from push_endpoints")
        rows = cur.fetchall()

    m = {}
    for user_id, endpoint, p256dh, auth in rows:
        m[user_id] = {"endpoint": endpoint, "keys": {"p256dh": p256dh, "auth": auth}}
    return m


def load_all_subscriptions(conn: psycopg.Connection) -> Dict[Tuple[str, date], List[str]]:
    """
    returns: (facility_id, date_ymd) -> [user_id...]
    """
    with conn.cursor(row_factory=tuple_row) as cur:
        cur.execute("""
            select facility_id, date_ymd, user_id
            from subscriptions
            where enabled = true
        """)
        rows = cur.fetchall()

    m: Dict[Tuple[str, date], List[str]] = {}
    for facility_id, date_ymd, user_id in rows:
        key = (str(facility_id), date_ymd)
        m.setdefault(key, []).append(user_id)
    return m


def load_snapshot_map(
    conn: psycopg.Connection,
    facility_ids: List[str],
    date_list: List[date],
) -> Dict[Tuple[str, date], Set[str]]:
    """
    returns: (facility_id, date_ymd) -> set(slot_key)
    batchë¡œ ì „ë¶€ ì½ì–´ì™€ ë©”ëª¨ë¦¬ì—ì„œ diff
    """
    if not facility_ids or not date_list:
        return {}

    with conn.cursor(row_factory=tuple_row) as cur:
        cur.execute("""
            select facility_id, date_ymd, slot_key
            from slots_snapshot
            where facility_id = any(%s) and date_ymd = any(%s)
        """, (facility_ids, date_list))
        rows = cur.fetchall()

    m: Dict[Tuple[str, date], Set[str]] = {}
    for facility_id, date_ymd, slot_key in rows:
        key = (str(facility_id), date_ymd)
        m.setdefault(key, set()).add(slot_key)
    return m


def upsert_snapshot(conn: psycopg.Connection, facility_id: str, date_ymd: date, slots: Set[str]) -> None:
    ts = utcnow()
    if not slots:
        # ìŠ¬ë¡¯ì´ ì—†ëŠ” ë‚ ë„ last_seenì„ ë‚¨ê¸°ê³  ì‹¶ìœ¼ë©´ ë³„ë„ í…Œì´ë¸”ë¡œ ê´€ë¦¬í•˜ëŠ” í¸ì´ ë‚«ë‹¤.
        return

    with conn.cursor() as cur:
        for sk in slots:
            cur.execute("""
                insert into slots_snapshot (facility_id, date_ymd, slot_key, first_seen_at, last_seen_at)
                values (%s, %s, %s, %s, %s)
                on conflict (facility_id, date_ymd, slot_key)
                do update set last_seen_at = excluded.last_seen_at
            """, (facility_id, date_ymd, sk, ts, ts))
    conn.commit()


def load_already_sent(conn: psycopg.Connection, user_id: str, facility_id: str, date_ymd: date, slot_keys: List[str]) -> Set[str]:
    if not slot_keys:
        return set()
    with conn.cursor(row_factory=tuple_row) as cur:
        cur.execute("""
            select slot_key
            from sent_log
            where user_id = %s and facility_id = %s and date_ymd = %s and slot_key = any(%s)
        """, (user_id, facility_id, date_ymd, slot_keys))
        rows = cur.fetchall()
    return {r[0] for r in rows}


def mark_sent(conn: psycopg.Connection, user_id: str, facility_id: str, date_ymd: date, slot_keys: List[str]) -> None:
    if not slot_keys:
        return
    ts = utcnow()
    with conn.cursor() as cur:
        for sk in slot_keys:
            cur.execute("""
                insert into sent_log (user_id, facility_id, date_ymd, slot_key, sent_at)
                values (%s, %s, %s, %s, %s)
                on conflict (user_id, facility_id, date_ymd, slot_key) do nothing
            """, (user_id, facility_id, date_ymd, sk, ts))
    conn.commit()


# -------------------------
# Push
# -------------------------
def send_push(subscription_info: dict, title: str, body: str) -> None:
    vapid_private = os.environ["VAPID_PRIVATE_KEY"]
    vapid_subject = os.environ["VAPID_SUBJECT"]

    payload = json.dumps({"title": title, "body": body}, ensure_ascii=False)
    webpush(
        subscription_info=subscription_info,
        data=payload,
        vapid_private_key=vapid_private,
        vapid_claims={"sub": vapid_subject},
    )


# -------------------------
# Crawl adapter (repo dependent)
# -------------------------
def crawl_all() -> Tuple[Dict[str, str], Dict[str, Dict[str, List[str]]]]:
    """
    Search_Tennis_Flyì˜ tennis_core.run_all()ì„ ê¸°ì¤€ìœ¼ë¡œ ì‘ì„±.
    ê¸°ëŒ€ í˜•íƒœ:
      facilities: { rid(str): "ì‹œì„¤ëª…" }
      availability: { rid(str): { "YYYYMMDD": [ "HH:MM", ... ] } }
    """
    res = tennis_core.run_all()

    # run_all()ì´ (facilities, availability) íŠœí”Œì´ë©´ ê·¸ëŒ€ë¡œ
    if isinstance(res, tuple) and len(res) == 2:
        facilities, availability = res
        return facilities, availability

    # í˜¹ì‹œ dictë¡œ í•œ ë²ˆì— ì£¼ëŠ” í˜•íƒœë©´ ì—¬ê¸°ì—ì„œ ë§ì¶°ì£¼ê¸°
    # (í•„ìš”í•˜ë©´ ë„ˆ run_all í˜•íƒœ ì•Œë ¤ì£¼ë©´ ë” ì •í™•íˆ ë§ì¶°ì¤„ê²Œ)
    raise RuntimeError("tennis_core.run_all() return shape not supported. Expected (facilities, availability).")


# -------------------------
# Main
# -------------------------
def main():
    # í•„ìˆ˜ env
    database_url = os.environ["DATABASE_URL"]
    # publicì€ í˜ì´ì§€ì—ì„œ ì“°ëŠ” ê²½ìš°ê°€ ë§ì•„ envë¡œ ì—†ì–´ë„ ë˜ì§€ë§Œ, ì„¸íŠ¸ë¡œ ê´€ë¦¬í•˜ëŠ” í¸ì´ ì¢‹ìŒ
    _ = os.environ.get("VAPID_PUBLIC_KEY", "")  # optional for server-side sending
    _ = os.environ["VAPID_PRIVATE_KEY"]
    _ = os.environ["VAPID_SUBJECT"]
    snapshot_rows = []  # (facility_id, date_ymd, slot_key, ts, ts)
    sent_rows = []      # (user_id, facility_id, date_ymd, slot_key, ts)
    ts_now = utcnow()

    with psycopg.connect(database_url) as conn:
        ensure_schema(conn)

        # 1) í¬ë¡¤ë§ (ì „ì²´)
        facilities, availability = crawl_all()
        print(f"[INFO] crawled facilities={len(availability)}")

        # 2) ì´ë²ˆ í¬ë¡¤ì—ì„œ ë“±ì¥í•˜ëŠ” facility/date ëª©ë¡ ë½‘ê¸°
        facility_ids = sorted([str(fid) for fid in availability.keys()])
        date_keys: Set[str] = set()
        for _, day_map in availability.items():
            for dk in day_map.keys():
                if dk and len(dk) == 8:
                    date_keys.add(dk)
        date_list = sorted([ymd_str_to_date(dk) for dk in date_keys])
        print(f"[INFO] snapshot preload facility_ids={len(facility_ids)} dates={len(date_list)}")

        # 3) ìŠ¤ëƒ…ìƒ· preload(ë°°ì¹˜)
        old_map = load_snapshot_map(conn, facility_ids, date_list)

        # 4) êµ¬ë…/ì—”ë“œí¬ì¸íŠ¸ preload
        subs_map = load_all_subscriptions(conn)
        endpoints = load_all_endpoints(conn)

        # 5) ì „ì²´ë¥¼ ëŒë©´ì„œ diff ê³„ì‚°
        total_added_pairs = 0
        total_added_slots = 0
        total_push_requests = 0

        for facility_id, day_map in availability.items():
            fid = str(facility_id)
            fname = facilities.get(fid, f"RID {fid}")

            for date_key, times in day_map.items():
                if not date_key or len(date_key) != 8:
                    continue
                d = ymd_str_to_date(date_key)

                new_slots = {slot_key_from_time(t) for t in (times or [])}
                key = (fid, d)
                old_slots = old_map.get(key, set())

                # âœ… ì²« ì‹¤í–‰(ìŠ¤ëƒ…ìƒ· ì—†ìŒ): baselineë§Œ ì €ì¥í•˜ê³  ì•Œë¦¼ ìŠ¤í‚µ
                if not old_slots:
                    if new_slots:
                        for sk in new_slots:
                            snapshot_rows.append((fid, d, sk, ts_now, ts_now))
                    old_map[key] = set(new_slots)
                    continue

                added = new_slots - old_slots

                # ë³€í™” ì—†ìŒ: snapshotë§Œ ê°±ì‹ (ê¸°ë³¸ì€ upsertë¡œ last_seen ê°±ì‹ )
                if not added:
                    if new_slots:
                        for sk in new_slots:
                            snapshot_rows.append((fid, d, sk, ts_now, ts_now))
                    old_map[key] = set(new_slots)
                    continue

                # âœ… addedê°€ ìˆì„ ë•Œë§Œ êµ¬ë…ì ë§¤ì¹­
                users = subs_map.get(key, [])
                if not users:
                    # êµ¬ë…ìê°€ ì—†ìœ¼ë©´ ìŠ¤ëƒ…ìƒ·ë§Œ ê°±ì‹ 
                    if new_slots:
                        for sk in new_slots:
                            snapshot_rows.append((fid, d, sk, ts_now, ts_now))
                    old_map[key] = set(new_slots)

                    continue

                total_added_pairs += 1
                total_added_slots += len(added)

                added_list_sorted = sorted(list(added))

                for user_id in users:
                    sub_info = endpoints.get(user_id)
                    if not sub_info:
                        continue

                    already_sent = load_already_sent(conn, user_id, fid, d, added_list_sorted)
                    to_send = [sk for sk in added_list_sorted if sk not in already_sent]
                    if not to_send:
                        continue

                    preview = ", ".join(to_send[:6])
                    more = "" if len(to_send) <= 6 else f" ì™¸ {len(to_send)-6}ê°œ"
                    title = "ğŸ¾ ì˜ˆì•½ ì˜¤í”ˆ"
                    body = f"{fname} {d.strftime('%m/%d')} ì‹ ê·œ ìŠ¬ë¡¯: {preview}{more}"

                    try:
                        send_push(sub_info, title, body)
                        mark_sent(conn, user_id, fid, d, to_send)
                        total_push_requests += 1
                    except WebPushException as e:
                        # ì‹¤íŒ¨í•´ë„ snapshotì€ ê³„ì† ê°±ì‹ í•´ì•¼ ë‹¤ìŒ diffê°€ ì •ìƒ ë™ì‘
                        code = getattr(getattr(e, "response", None), "status_code", None)
                        print(f"[PUSH_FAIL] user={user_id} fid={fid} date={date_key} status={code} err={e}")

                # ìŠ¤ëƒ…ìƒ· ê°±ì‹ (ìƒˆ ìŠ¬ë¡¯ í¬í•¨)
                if new_slots:
                    for sk in new_slots:
                        snapshot_rows.append((fid, d, sk, ts_now, ts_now))
                old_map[key] = set(new_slots)
                print(f"[DIFF] {fid} {date_key} old={len(old_slots)} new={len(new_slots)} added={len(added)} users={len(users)}")
        # --- flush snapshots (bulk upsert) ---
        if snapshot_rows:
            with conn.cursor() as cur:
                cur.executemany(
                    """
                    insert into slots_snapshot (facility_id, date_ymd, slot_key, first_seen_at, last_seen_at)
                    values (%s, %s, %s, %s, %s)
                    on conflict (facility_id, date_ymd, slot_key)
                    do update set last_seen_at = excluded.last_seen_at
                    """,
                    snapshot_rows
                )

        # --- flush sent_log (bulk insert) ---
        if sent_rows:
            with conn.cursor() as cur:
                cur.executemany(
                    """
                    insert into sent_log (user_id, facility_id, date_ymd, slot_key, sent_at)
                    values (%s, %s, %s, %s, %s)
                    on conflict (user_id, facility_id, date_ymd, slot_key)
                    do nothing
                    """,
                    sent_rows
                )

        conn.commit()

        print(f"[SUMMARY] added_pairs={total_added_pairs} added_slots={total_added_slots} push_requests={total_push_requests}")


if __name__ == "__main__":
    main()
